---
layout: post
title: HDFS 的小文件储存问题
---

在日常使用 HDFS 的时候，有时候会出现某种需求，需要向 HDFS 中写入大量的小文件。比如做爬虫的时候
可能会把爬下来的网页以一个文件存入 HDFS。

<!--more-->

## 小文件造成的问题

大量的小文件很快就会导致 HDFS 中存在几百万甚至千万以及亿级别的文件。然后由于 HDFS 的文件索引是
记录在 namenode 的内存中的，所以最后 namenode 的内存会成为集群的瓶颈。而且 HDFS 本身并不是
设计用来获取小文件的，HDFS 适合大文件的批量读取，所以太多的小文件会影响他的使用性能。

MapReduce 也会受到小文件的影响，因为 Map 任务每次会读取一块文件作为输入。若文件太小，会导致
每次 Map 任务的输入太少，造成系统需要更多的 Map 任务进程运行。

## 小文件产生的原因

小文件可能有两种来源：

  1. 每个小文件在逻辑上是一大块文件的拆分，典型的比如说各种日志。这种场景我们可以将这些文件合并
  成块写入 HDFS。
  2. 这些文件本质上就是小文件，比如说大量的图片文件和爬取的网页文件。这些需要特殊的处理。

## HAR Files

Hadoop Archives (HAR files) 是建立在 HDFS 上的一个文件系统，他会在内部使用 MapReduce 作业
将小文件合并成大文件，然后对大文件里面的文件在做一个索引。这样通过一个二级索引，HAR 就可以避免
保存太多的小文件。

但是因为每次获取数据都需要两次索引的查询，所以 HAR 的读取性能较 HDFS 是比较低的。

## Sequence Files

顺序文件把文件的路径当作 key，把文件的内容当作 value。这样的文件就可以以 key-vlaue 对的形式
存放在文件中。另外一种 MapFile 类型除了用顺序储存外，还对 key 做了一个索引，HBase 就是使用
这种方式储存的。

顺序文件目前是 HDFS 小文件问题的比较好的解决方案了。
