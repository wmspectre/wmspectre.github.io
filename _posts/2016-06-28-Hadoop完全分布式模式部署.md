---
layout: post
title: Hadoop完全分布式模式部署
---

## 介绍

Hadoop 的部署方式有三种：单机模式，伪分布式和完全分布式。其中单机模式和伪分布式都是在单机上部署的，便于学习和调试，
在生产环境中，是必需使用完全分布式模式来部署 Hadoop 集群的。本文就介绍完全分布式 Hadoop 集群的部署方法。

<!--more-->

## 安装前的准备

### 硬件

本文使用3台虚拟机 hadoop1、hadoop2、hadoop3。一台作为 namenode，两台作为 datanode，每台配置为2核4G内存。在正式的生产环境中，一般会针对不同类型的 node，给予不同的配置。

### 操作系统

Hadoop 可以在 Linux/Windows 系统上运行，但是在 Windows 上测试并不是很完全，所以建议在 Linux 系统上部署。
本文使用 Ubuntu 14.04 长期支持版。

### 需要的软件

* Hadoop - 本文采用的是 Hadoop 2.5.2 版本，可以在[官网](http://hadoop.apache.org/)上下载相应版本的压缩包。
* Java - 可以在 [Oracle](http://www.oracle.com/technetwork/java/javase/downloads/index-jsp-138363.html) 上下载最新版本的 Java，本文使用的是 `jdk1.8.0_92`。
* ssh - 安装 ssh 程序，并确保 sshd 进程在运行，不同 Hadoop 实例之前需要通过 ssh 通信。

## 配置

### shh 免密码登陆

设置 ssh 免密码登陆，可以让服务器集群之间使用 ssh 通信时不需要手动输入密码。具体的步骤参见我的另一篇文章[ssh设置免密码登陆](http://wmspectre.github.io/2016/06/28/ssh%E5%85%8D%E5%AF%86%E7%A0%81%E7%99%BB%E9%99%86%E9%85%8D%E7%BD%AE/)。

### 设置 hostname

打开 `/etc/hosts`，在其中添加三个服务器的配置，例如：

```shell
192.16.0.1 hadoop1
192.16.0.2 hadoop2
192.16.0.3 hadoop3
```

### 配置 Hadoop

解压压缩文件，放到安装目录下，比如 `/opt/hadoop-2.5.2`，进入 `etc/hadoop` 文件夹下，里面是 Hadoop 的配置文件。

首先打开 `hadoop-env.sh` 文件，在里面设置 `JAVA_HOME` 环境变量的值。

打开 `core-site.xml`，加入配置：

```xml
<configuration>
  <property>
    <name>fs.default.name</name>
    <value>hdfs://hadoop1:9000</value>
  </property>
  <property>
    <name>hadoop.tmp.dir</name>
    <value>file:/mnt/hadoop/tmp</value>
  </property>
</configuration>
```

然后打开 `hdfs-site.xml`，加入配置：

```xml
<configuration>
  <property>
    <name>dfs.namenode.secondary.http-address</name>
    <value>hbase1:50090</value>
  </property>
  <property>
    <name>dfs.namenode.name.dir</name>
    <value>file:/mnt/hadoop/dfs/name</value>
  </property>
  <property>
    <name>dfs.datanode.data.dir</name>
    <value>file:/mnt/hadoop/dfs/data</value>
  </property>
  <property>
    <name>dfs.replication</name>
    <value>2</value>
  </property>
  <property>
    <name>dfs.webhdfs.enabled</name>
    <value>true</value>
  </property>
  <property>
    <name>dfs.support.append</name>
    <value>true</value>
  </property>
  <property>
    <name>dfs.support.broken.append</name>
    <value>true</value>
  </property>
</configuration>
```

其中，`namenode.name.dir` 是 namenode 的数据目录，`datanode.data.dir` 是 datanode 的数据目录，`namenode.secondary` 是二级 namenode，用于同步备份
 namenode 数据。这里我们把 namenode 和 secondary namenode 放在同一台机器上。`dfs.replication` 是副本集的数量。

最后打开 `slaves` 文件，写入：

```shell
hadoop2
hadoop3
```

此文件定义了所有的 datanote。

配置完成后把 Hadoop 文件夹拷贝到另外两台服务器上：`scp -r hadoop-2.5.2/ hadoop2`。

## 运行 Hadoop

配置完成后，运行 Hadoop 很简单。首先在服务器的 `HADOOP_HOME` 目录下运行命令：`./bin/hdfs namenode -format` 进行格式化（每台服务器运行一遍）。
然后在 hadoop1 上运行命令：`./sbin/start-dfs.sh`，Master node 会自动启动 Slaves 服务器上的进程。启动完之后可以运行命令： `jps` 观察在运行
的 Java 进程。关闭 Hadoop 服务可以运行　`./sbin/stop-dfs.sh`。 
